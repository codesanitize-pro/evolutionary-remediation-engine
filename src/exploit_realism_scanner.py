#!/usr/bin/env python3
"""
Exploit Realism Scanner (ERS)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Detects simulated, mock, or fake exploit code in cybersecurity test files.
Ensures security professionals test against real-world threat patterns.

Weaknesses this tool addresses vs OMEGA StaticCodeAnalyzer:
  1. AST-based analysis (not just string matching)
  2. 120+ detection patterns (not 13)
  3. Realism scoring 0-100 (not binary pass/fail)
  4. Context-aware (comments vs code, function bodies vs names)
  5. Behavioral analysis (always-true, no-op, dead code)
  6. CVE validation (format, year range, known fake IDs)
  7. Scans any directory/file (not hardcoded to 2 files)
  8. Control flow analysis (unreachable branches, empty handlers)
  9. Multi-format reporting (JSON, Markdown, terminal)

Usage:
    python exploit_realism_scanner.py <path>
    python exploit_realism_scanner.py <path> --output report.json
    python exploit_realism_scanner.py <path> --format markdown --output report.md
    python exploit_realism_scanner.py <path> --strict --min-score 70

    # Competition/Enterprise Readiness Mode:
    python exploit_realism_scanner.py <path> --competition
    python exploit_realism_scanner.py <path> --competition --tool-type exploit
    python exploit_realism_scanner.py <path> --competition --output readiness.json
"""

from __future__ import annotations

import ast
import json
import re
import sys
import time
from collections import defaultdict
from dataclasses import asdict, dataclass, field
from enum import Enum
from pathlib import Path
from textwrap import dedent
from typing import Any


# ============================================================================
# DATA MODELS
# ============================================================================

class Severity(str, Enum):
    CRITICAL = "CRITICAL"
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"
    INFO = "INFO"


class Category(str, Enum):
    MOCK_NAMING = "mock_naming"
    STUB_IMPL = "stub_implementation"
    FAKE_DATA = "fake_data"
    FAKE_CVE = "fake_cve"
    NOOP_FUNCTION = "noop_function"
    ALWAYS_PASS = "always_pass"
    TOY_PATTERN = "toy_pattern"
    MISSING_REALISM = "missing_realism"
    DEAD_CODE = "dead_code"
    PLACEHOLDER = "placeholder"
    SIMULATED_PAYLOAD = "simulated_payload"
    WEAK_ERROR_HANDLING = "weak_error_handling"


class ToolType(str, Enum):
    """Auto-detected type of security tool being analyzed."""
    EXPLOIT = "exploit"
    SCANNER = "scanner"
    FUZZER = "fuzzer"
    CRYPTO = "crypto_tool"
    FORENSIC = "forensic"
    RECON = "recon"
    GENERAL = "general_security"


class ReadinessStatus(str, Enum):
    PASS = "PASS"
    FAIL = "FAIL"
    WARN = "WARN"


@dataclass
class Finding:
    """A single detected issue in the scanned code."""
    category: Category
    severity: Severity
    message: str
    file_path: str
    line_number: int | None = None
    code_snippet: str | None = None
    confidence: float = 0.0  # 0.0 - 1.0
    suggestion: str | None = None

    def to_dict(self) -> dict:
        d = {
            "category": self.category.value,
            "severity": self.severity.value,
            "message": self.message,
            "file_path": self.file_path,
            "line_number": self.line_number,
            "confidence": round(self.confidence, 2),
        }
        if self.code_snippet:
            d["code_snippet"] = self.code_snippet[:200]
        if self.suggestion:
            d["suggestion"] = self.suggestion
        return d


@dataclass
class FileScore:
    """Realism score for a single file."""
    file_path: str
    realism_score: int  # 0-100
    findings: list[Finding] = field(default_factory=list)
    lines_of_code: int = 0
    functions_analyzed: int = 0
    has_network_calls: bool = False
    has_system_calls: bool = False
    has_crypto_ops: bool = False
    has_real_payloads: bool = False
    grade: str = ""  # A/B/C/D/F

    def __post_init__(self):
        if not self.grade:
            self.grade = self._compute_grade()

    def _compute_grade(self) -> str:
        if self.realism_score >= 90:
            return "A"
        elif self.realism_score >= 75:
            return "B"
        elif self.realism_score >= 60:
            return "C"
        elif self.realism_score >= 40:
            return "D"
        return "F"


@dataclass
class ScanReport:
    """Complete scan report."""
    scan_path: str
    files_scanned: int = 0
    files_flagged: int = 0
    total_findings: int = 0
    critical_findings: int = 0
    average_realism_score: float = 0.0
    file_scores: list[FileScore] = field(default_factory=list)
    scan_duration_seconds: float = 0.0
    category_breakdown: dict[str, int] = field(default_factory=dict)

    def to_dict(self) -> dict:
        return {
            "scan_path": self.scan_path,
            "files_scanned": self.files_scanned,
            "files_flagged": self.files_flagged,
            "total_findings": self.total_findings,
            "critical_findings": self.critical_findings,
            "average_realism_score": round(self.average_realism_score, 1),
            "scan_duration_seconds": round(self.scan_duration_seconds, 2),
            "category_breakdown": self.category_breakdown,
            "file_scores": [
                {
                    "file": fs.file_path,
                    "score": fs.realism_score,
                    "grade": fs.grade,
                    "findings_count": len(fs.findings),
                    "lines": fs.lines_of_code,
                    "has_network": fs.has_network_calls,
                    "has_system": fs.has_system_calls,
                    "has_crypto": fs.has_crypto_ops,
                    "findings": [f.to_dict() for f in fs.findings],
                }
                for fs in self.file_scores
            ],
        }

    def to_markdown(self) -> str:
        lines = [
            "# Exploit Realism Scanner Report",
            "",
            f"**Scanned:** `{self.scan_path}`  ",
            f"**Files:** {self.files_scanned} scanned, {self.files_flagged} flagged  ",
            f"**Findings:** {self.total_findings} total, {self.critical_findings} critical  ",
            f"**Average Realism Score:** {self.average_realism_score:.0f}/100  ",
            f"**Duration:** {self.scan_duration_seconds:.2f}s  ",
            "",
            "---",
            "",
            "## Category Breakdown",
            "",
            "| Category | Count |",
            "|----------|-------|",
        ]
        for cat, count in sorted(self.category_breakdown.items(), key=lambda x: -x[1]):
            lines.append(f"| {cat.replace('_', ' ').title()} | {count} |")

        lines.extend(["", "---", "", "## File Results", ""])

        for fs in sorted(self.file_scores, key=lambda x: x.realism_score):
            emoji = {"A": "+", "B": "+", "C": "~", "D": "-", "F": "!"}
            mark = emoji.get(fs.grade, "?")
            lines.append(f"### [{fs.grade}] `{fs.file_path}` (Score: {fs.realism_score}/100)")
            lines.append("")
            if fs.findings:
                lines.append("| Severity | Category | Line | Message |")
                lines.append("|----------|----------|------|---------|")
                for f in fs.findings:
                    lines.append(
                        f"| {f.severity.value} | {f.category.value} | "
                        f"{f.line_number or '-'} | {f.message[:80]} |"
                    )
                lines.append("")
            else:
                lines.append("No issues found.")
                lines.append("")

        lines.extend([
            "---",
            "",
            "*Generated by Exploit Realism Scanner (ERS)*",
        ])
        return "\n".join(lines)


@dataclass
class ReadinessCheck:
    """A single competition readiness check result."""
    check_id: str
    check_name: str
    status: ReadinessStatus
    message: str
    fix: str | None = None
    before_example: str | None = None
    after_example: str | None = None
    weight: float = 1.0  # How important this check is (0.0-1.0)

    def to_dict(self) -> dict:
        d = {
            "check_id": self.check_id,
            "check_name": self.check_name,
            "status": self.status.value,
            "message": self.message,
        }
        if self.fix:
            d["fix"] = self.fix
        if self.before_example:
            d["before_example"] = self.before_example
        if self.after_example:
            d["after_example"] = self.after_example
        return d


@dataclass
class CompetitionReport:
    """Full competition readiness report."""
    file_path: str
    detected_tool_type: str
    overall_verdict: str  # "COMPETITION READY" / "NEEDS WORK" / "WILL FAIL"
    pass_probability: float  # 0.0-1.0
    realism_score: int
    checks: list[ReadinessCheck] = field(default_factory=list)
    remediation_summary: list[str] = field(default_factory=list)

    def to_dict(self) -> dict:
        return {
            "file_path": self.file_path,
            "detected_tool_type": self.detected_tool_type,
            "overall_verdict": self.overall_verdict,
            "pass_probability": round(self.pass_probability, 2),
            "realism_score": self.realism_score,
            "checks_passed": sum(1 for c in self.checks if c.status == ReadinessStatus.PASS),
            "checks_total": len(self.checks),
            "checks": [c.to_dict() for c in self.checks],
            "remediation_summary": self.remediation_summary,
        }

    def to_markdown(self) -> str:
        lines = [
            f"# Competition Readiness Report",
            "",
            f"**File:** `{self.file_path}`  ",
            f"**Tool Type:** {self.detected_tool_type}  ",
            f"**Verdict:** {self.overall_verdict}  ",
            f"**Pass Probability:** {self.pass_probability:.0%}  ",
            f"**Realism Score:** {self.realism_score}/100  ",
            "",
            "---",
            "",
            "## Checklist",
            "",
            "| Status | Check | Details |",
            "|--------|-------|---------|",
        ]
        for c in self.checks:
            icon = {"PASS": "OK", "FAIL": "XX", "WARN": "!!"}[c.status.value]
            lines.append(f"| {icon} | {c.check_name} | {c.message[:60]} |")

        if self.remediation_summary:
            lines.extend(["", "---", "", "## Remediation Steps", ""])
            for i, step in enumerate(self.remediation_summary, 1):
                lines.append(f"{i}. {step}")

        fix_checks = [c for c in self.checks if c.status == ReadinessStatus.FAIL and c.fix]
        if fix_checks:
            lines.extend(["", "---", "", "## Fix Details", ""])
            for c in fix_checks:
                lines.append(f"### {c.check_name}")
                lines.append("")
                lines.append(f"**Problem:** {c.message}")
                lines.append("")
                lines.append(f"**Fix:** {c.fix}")
                if c.before_example and c.after_example:
                    lines.append("")
                    lines.append("**Before:**")
                    lines.append(f"```python\n{c.before_example}\n```")
                    lines.append("")
                    lines.append("**After:**")
                    lines.append(f"```python\n{c.after_example}\n```")
                lines.append("")

        lines.extend([
            "---",
            "",
            "*Generated by Exploit Realism Scanner (ERS) - Competition Mode*",
        ])
        return "\n".join(lines)


# ============================================================================
# DETECTION PATTERNS
# ============================================================================

# Variable/function name patterns that indicate mock/fake code
MOCK_NAME_PATTERNS: list[tuple[re.Pattern, str, float]] = [
    (re.compile(r'\b(?:mock|mocked)_\w+', re.I), "Mock-prefixed identifier", 0.9),
    (re.compile(r'\b(?:fake|faked)_\w+', re.I), "Fake-prefixed identifier", 0.9),
    (re.compile(r'\bdummy_\w+', re.I), "Dummy-prefixed identifier", 0.85),
    (re.compile(r'\bstub_\w+', re.I), "Stub-prefixed identifier", 0.85),
    (re.compile(r'\bplaceholder_\w+', re.I), "Placeholder-prefixed identifier", 0.9),
    (re.compile(r'\bsimulated?_\w+', re.I), "Simulated-prefixed identifier", 0.9),
    (re.compile(r'\btest_exploit\b', re.I), "Test exploit function name", 0.7),
    (re.compile(r'\bsample_\w*(?:exploit|payload|attack|vuln)', re.I), "Sample exploit name", 0.85),
    (re.compile(r'\btoy_\w+', re.I), "Toy-prefixed identifier", 0.8),
    (re.compile(r'\bexample_\w*(?:exploit|attack|payload)', re.I), "Example exploit name", 0.8),
    (re.compile(r'\bdemo_\w*(?:exploit|attack|payload)', re.I), "Demo exploit name", 0.75),
]

# Code patterns indicating stub/placeholder implementations
STUB_PATTERNS: list[tuple[re.Pattern, str, float]] = [
    (re.compile(r'raise\s+NotImplementedError'), "NotImplementedError raised", 0.95),
    (re.compile(r'#\s*TODO[:\s]', re.I), "TODO comment in security code", 0.6),
    (re.compile(r'#\s*FIXME[:\s]', re.I), "FIXME comment in security code", 0.65),
    (re.compile(r'#\s*HACK[:\s]', re.I), "HACK comment in security code", 0.5),
    (re.compile(r'#\s*XXX[:\s]', re.I), "XXX marker in security code", 0.6),
    (re.compile(r'pass\s*$', re.M), "Empty pass statement", 0.7),
    (re.compile(r'\.\.\.'), "Ellipsis placeholder", 0.75),
    (re.compile(r'return\s+None\s*$', re.M), "Returns None (potential stub)", 0.4),
]

# Fake data patterns
FAKE_DATA_PATTERNS: list[tuple[re.Pattern, str, float]] = [
    # Fake IPs used in toy code
    (re.compile(r'["\']127\.0\.0\.1["\']'), "Localhost IP in exploit code", 0.7),
    (re.compile(r'["\']192\.168\.\d+\.\d+["\']'), "Private RFC1918 IP in exploit", 0.6),
    (re.compile(r'["\']10\.\d+\.\d+\.\d+["\']'), "Private RFC1918 IP in exploit", 0.6),
    (re.compile(r'["\']0\.0\.0\.0["\']'), "Wildcard IP in exploit", 0.65),
    # Fake domains
    (re.compile(r'["\'](?:example|test|localhost|fake|dummy)\.(?:com|org|net)["\']', re.I),
     "Fake domain in exploit code", 0.85),
    (re.compile(r'["\'](?:target|victim)\.(?:com|org|net)["\']', re.I),
     "Generic target domain", 0.8),
    # Fake credentials
    (re.compile(r'["\'](?:password|admin|root|test|1234|qwerty|changeme)["\']', re.I),
     "Toy credential in exploit", 0.75),
    (re.compile(r'["\'](?:username|user|admin)["\']', re.I),
     "Generic username placeholder", 0.5),
    # Placeholder ports
    (re.compile(r'port\s*=\s*(?:1234|9999|8888|4444|1337)\b'),
     "Common placeholder port", 0.6),
    # Fake shellcode
    (re.compile(r'\\x90{4,}'), "NOP sled (only NOPs = toy shellcode)", 0.85),
    (re.compile(r'["\']A{10,}["\']'), "Buffer of repeated A's (toy overflow)", 0.8),
    (re.compile(r'b["\']\\x41{10,}'), "Repeated 0x41 buffer (toy)", 0.8),
    (re.compile(r'shellcode\s*=\s*["\']\\x90'), "Shellcode starting with NOPs only", 0.7),
    # Fake hashes
    (re.compile(r'["\'](?:0{32}|a{32}|f{32}|1{32})["\']', re.I),
     "Fake hash (repeated character)", 0.9),
    (re.compile(r'["\'](?:deadbeef|cafebabe|baadf00d)', re.I),
     "Debug magic bytes as hash", 0.85),
]

# CVE validation patterns
FAKE_CVE_PATTERNS: list[tuple[re.Pattern, str, float]] = [
    (re.compile(r'CVE-\d{4}-X{3,}', re.I), "Placeholder CVE with X's", 0.95),
    (re.compile(r'CVE-\d{4}-0{4,}'), "CVE with all zeros", 0.9),
    (re.compile(r'CVE-\d{4}-1234\b'), "CVE-YYYY-1234 (common placeholder)", 0.85),
    (re.compile(r'CVE-\d{4}-9999\b'), "CVE-YYYY-9999 (common placeholder)", 0.8),
    (re.compile(r'CVE-(?:1999|2000|2001)-\d+'), "Very old CVE (likely academic example)", 0.5),
    (re.compile(r'CVE-20[3-9]\d-'), "Future CVE year (doesn't exist yet)", 0.95),
    (re.compile(r'CVE-XXXX', re.I), "CVE-XXXX placeholder", 0.95),
]

# Toy/academic patterns
TOY_PATTERNS: list[tuple[re.Pattern, str, float]] = [
    (re.compile(r'print\s*\(\s*["\'](?:exploit|attack|hack|pwned|owned|shell|success)',
                re.I), "Print-based exploit confirmation (toy)", 0.85),
    (re.compile(r'print\s*\(\s*["\'](?:vulnerability found|target compromised)',
                re.I), "Print-based vuln confirmation (toy)", 0.85),
    (re.compile(r'time\.sleep\s*\(\s*\d+\s*\).*#.*(?:simulate|pretend|fake)',
                re.I), "Sleep simulating exploit delay", 0.9),
    (re.compile(r'#\s*(?:simulated|simulating|fake|pretend|placeholder|for demo)',
                re.I), "Comment admitting simulation", 0.9),
    (re.compile(r'["\'](?:This is a (?:simulated|fake|test|demo) )',
                re.I), "String admitting simulation", 0.95),
    (re.compile(r'random\.(?:randint|choice|random)\s*\(.*#.*(?:fake|simul|mock)',
                re.I), "Random data pretending to be exploit result", 0.9),
    (re.compile(r'(?:base64\.b64encode|base64\.b64decode)\s*\(.*["\'](?:test|demo|fake)',
                re.I), "Base64 with fake data (toy crypto)", 0.8),
]

# Simulated payload patterns
SIMULATED_PAYLOAD_PATTERNS: list[tuple[re.Pattern, str, float]] = [
    (re.compile(r'payload\s*=\s*["\'](?:test|demo|fake|sample|example)',
                re.I), "Named fake payload", 0.9),
    (re.compile(r'exploit_code\s*=\s*["\']'), "Exploit as hardcoded string", 0.7),
    (re.compile(r'shellcode\s*=\s*["\']["\']'), "Empty shellcode", 0.95),
    (re.compile(r'malware\s*=\s*["\']', re.I), "Malware as string literal", 0.8),
    (re.compile(r'(?:payload|exploit|shellcode)\s*=\s*b?["\']hello',
                re.I), "Hello-world payload", 0.95),
    (re.compile(r'requests\.(?:get|post)\s*\(\s*["\']https?://(?:example|test|localhost)',
                re.I), "HTTP request to fake target", 0.85),
]

# Weak error handling patterns
WEAK_ERROR_PATTERNS: list[tuple[re.Pattern, str, float]] = [
    (re.compile(r'except\s*:\s*(?:pass|\.\.\.)\s*$', re.M),
     "Bare except with pass (swallows all errors)", 0.8),
    (re.compile(r'except\s+Exception\s*:\s*(?:pass|\.\.\.)\s*$', re.M),
     "Broad except with pass", 0.7),
    (re.compile(r'except\s*:\s*$', re.M), "Bare except (empty handler)", 0.85),
]

# Indicators of REAL exploit code (boost realism score)
REALISM_INDICATORS: list[tuple[re.Pattern, str, int]] = [
    # Network libraries
    (re.compile(r'import\s+socket\b'), "Uses socket library", 10),
    (re.compile(r'from\s+scapy'), "Uses scapy (packet crafting)", 15),
    (re.compile(r'import\s+paramiko'), "Uses paramiko (SSH)", 12),
    (re.compile(r'import\s+requests\b'), "Uses requests library", 5),
    (re.compile(r'import\s+urllib'), "Uses urllib", 5),
    (re.compile(r'import\s+http\.client'), "Uses http.client", 8),
    (re.compile(r'import\s+ftplib'), "Uses ftplib", 8),
    (re.compile(r'import\s+smtplib'), "Uses smtplib", 8),
    (re.compile(r'import\s+telnetlib'), "Uses telnetlib", 8),
    (re.compile(r'from\s+impacket'), "Uses impacket (exploit framework)", 20),
    (re.compile(r'from\s+pwntools|from\s+pwn\b'), "Uses pwntools", 20),
    # System interaction
    (re.compile(r'import\s+subprocess'), "Uses subprocess", 8),
    (re.compile(r'import\s+ctypes'), "Uses ctypes (memory access)", 12),
    (re.compile(r'import\s+struct\b'), "Uses struct (binary packing)", 10),
    (re.compile(r'os\.(?:system|popen|exec)'), "OS command execution", 10),
    (re.compile(r'subprocess\.(?:run|Popen|call)'), "Subprocess execution", 10),
    # Crypto
    (re.compile(r'from\s+Crypto|from\s+cryptography'), "Uses real crypto library", 10),
    (re.compile(r'import\s+hashlib'), "Uses hashlib", 5),
    (re.compile(r'import\s+ssl\b'), "Uses SSL library", 8),
    # Real exploit patterns
    (re.compile(r'struct\.pack\s*\('), "Binary structure packing", 10),
    (re.compile(r'socket\.(?:connect|send|recv)'), "Raw socket operations", 12),
    (re.compile(r'\.recv\s*\(\d+\)'), "Network receive with buffer", 8),
    (re.compile(r'select\.select'), "Socket multiplexing", 8),
    (re.compile(r'threading\.Thread'), "Multi-threaded operation", 5),
    # Protocol-specific
    (re.compile(r'(?:HTTP|GET|POST|PUT|DELETE)\s+/'), "HTTP protocol construction", 8),
    (re.compile(r'Content-Type:|User-Agent:|Authorization:'), "HTTP header crafting", 6),
    (re.compile(r'\\r\\n\\r\\n'), "HTTP delimiter construction", 8),
    # Error handling
    (re.compile(r'except\s+(?:socket\.error|ConnectionRefusedError|TimeoutError)'),
     "Specific network error handling", 8),
    (re.compile(r'except\s+(?:struct\.error|ValueError)\s+as'),
     "Specific parsing error handling", 5),
]

# File extensions to scan
SECURITY_EXTENSIONS = {
    ".py", ".js", ".ts", ".rb", ".go", ".c", ".cpp", ".h",
    ".java", ".cs", ".rs", ".sh", ".bash", ".ps1", ".bat",
    ".pl", ".php", ".lua",
}


# ============================================================================
# AST ANALYZER (Python-specific deep analysis)
# ============================================================================

class ASTAnalyzer:
    """
    Analyzes Python AST for behavioral patterns that indicate
    fake/simulated exploit code.
    """

    def __init__(self, source: str, file_path: str):
        self.source = source
        self.file_path = file_path
        self.findings: list[Finding] = []
        self.functions_analyzed = 0
        self.has_network = False
        self.has_system = False
        self.has_crypto = False
        self.tree: ast.AST | None = None

    def analyze(self) -> list[Finding]:
        try:
            self.tree = ast.parse(self.source)
        except SyntaxError:
            return []

        self._check_imports()
        self._check_functions()
        self._check_classes()
        return self.findings

    def _check_imports(self):
        """Track what libraries are imported to assess realism."""
        for node in ast.walk(self.tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    self._classify_import(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    self._classify_import(node.module)

    def _classify_import(self, module_name: str):
        network_modules = {
            "socket", "requests", "urllib", "http", "ftplib",
            "smtplib", "telnetlib", "paramiko", "scapy", "impacket",
            "pwntools", "pwn", "aiohttp", "httpx",
        }
        system_modules = {
            "subprocess", "ctypes", "os", "shutil", "signal",
            "multiprocessing", "winreg",
        }
        crypto_modules = {
            "cryptography", "Crypto", "hashlib", "ssl", "hmac",
            "secrets",
        }
        root = module_name.split(".")[0]
        if root in network_modules:
            self.has_network = True
        if root in system_modules:
            self.has_system = True
        if root in crypto_modules:
            self.has_crypto = True

    def _check_functions(self):
        """Analyze function bodies for fake patterns."""
        for node in ast.walk(self.tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                self.functions_analyzed += 1
                self._analyze_function(node)

    def _analyze_function(self, func: ast.FunctionDef | ast.AsyncFunctionDef):
        name = func.name.lower()
        body = func.body

        # Security-related function names
        security_names = {
            "exploit", "attack", "scan", "payload", "inject",
            "overflow", "execute", "pwn", "hack", "brute",
            "fuzz", "crack", "decrypt", "escalate", "pivot",
            "exfiltrate", "backdoor", "reverse_shell", "bind_shell",
            "spray", "enumerate", "recon", "probe",
        }

        is_security_func = any(s in name for s in security_names)

        # Check 1: Empty or trivial function body
        if self._is_trivial_body(body):
            sev = Severity.HIGH if is_security_func else Severity.MEDIUM
            self.findings.append(Finding(
                category=Category.NOOP_FUNCTION,
                severity=sev,
                message=f"Function '{func.name}' has trivial/empty body",
                file_path=self.file_path,
                line_number=func.lineno,
                code_snippet=self._get_source_lines(func.lineno, func.lineno + 3),
                confidence=0.85,
                suggestion="Security functions should contain actual logic",
            ))

        # Check 2: Always returns True/False (bypass pattern)
        const_return = self._always_returns_constant(body)
        if const_return is not None and is_security_func:
            self.findings.append(Finding(
                category=Category.ALWAYS_PASS,
                severity=Severity.CRITICAL,
                message=f"Security function '{func.name}' always returns {const_return}",
                file_path=self.file_path,
                line_number=func.lineno,
                code_snippet=self._get_source_lines(func.lineno, func.lineno + 5),
                confidence=0.95,
                suggestion="Security functions should have conditional logic based on actual checks",
            ))

        # Check 3: Only prints (no real action)
        if is_security_func and self._only_prints(body):
            self.findings.append(Finding(
                category=Category.TOY_PATTERN,
                severity=Severity.HIGH,
                message=f"Security function '{func.name}' only prints messages (no real operations)",
                file_path=self.file_path,
                line_number=func.lineno,
                code_snippet=self._get_source_lines(func.lineno, func.lineno + 5),
                confidence=0.9,
                suggestion="Exploit functions should perform network/system operations, not just print",
            ))

        # Check 4: Security function with only sleep calls
        if is_security_func and self._only_sleeps(body):
            self.findings.append(Finding(
                category=Category.SIMULATED_PAYLOAD,
                severity=Severity.HIGH,
                message=f"Security function '{func.name}' only contains sleep() calls (simulating delay)",
                file_path=self.file_path,
                line_number=func.lineno,
                confidence=0.9,
                suggestion="Replace sleep-based simulation with actual exploit logic",
            ))

        # Check 5: Hardcoded return values in functions that should compute
        if is_security_func and self._has_hardcoded_results(body):
            self.findings.append(Finding(
                category=Category.FAKE_DATA,
                severity=Severity.HIGH,
                message=f"Security function '{func.name}' returns hardcoded results instead of computing",
                file_path=self.file_path,
                line_number=func.lineno,
                confidence=0.85,
                suggestion="Return computed results based on actual analysis, not hardcoded values",
            ))

    def _is_trivial_body(self, body: list[ast.stmt]) -> bool:
        """Check if function body is trivial (pass, ..., docstring only)."""
        meaningful = []
        for stmt in body:
            # Skip docstrings
            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Constant):
                continue
            meaningful.append(stmt)

        if not meaningful:
            return True
        if len(meaningful) == 1:
            stmt = meaningful[0]
            if isinstance(stmt, ast.Pass):
                return True
            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Constant):
                if stmt.value.value is ...:
                    return True
            if isinstance(stmt, ast.Raise) and isinstance(stmt.exc, ast.Call):
                if hasattr(stmt.exc.func, 'id') and stmt.exc.func.id == 'NotImplementedError':
                    return True
        return False

    def _always_returns_constant(self, body: list[ast.stmt]) -> Any | None:
        """Check if all return paths return the same constant."""
        returns = []
        for node in ast.walk(ast.Module(body=body, type_ignores=[])):
            if isinstance(node, ast.Return):
                if isinstance(node.value, ast.Constant):
                    returns.append(node.value.value)
                elif node.value is None:
                    returns.append(None)
                else:
                    return None  # Non-constant return found

        if returns and len(set(map(str, returns))) == 1:
            return returns[0]
        return None

    def _only_prints(self, body: list[ast.stmt]) -> bool:
        """Check if function body only contains print() calls."""
        meaningful = []
        for stmt in body:
            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Constant):
                continue  # Skip docstrings
            meaningful.append(stmt)

        if not meaningful:
            return False

        for stmt in meaningful:
            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Call):
                func = stmt.value.func
                if isinstance(func, ast.Name) and func.id == "print":
                    continue
                if isinstance(func, ast.Attribute) and func.attr in ("info", "debug", "warning"):
                    continue
            return False  # Non-print statement found
        return True

    def _only_sleeps(self, body: list[ast.stmt]) -> bool:
        """Check if function only has sleep calls and prints."""
        meaningful = []
        for stmt in body:
            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Constant):
                continue
            meaningful.append(stmt)

        if not meaningful:
            return False

        for stmt in meaningful:
            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Call):
                func = stmt.value.func
                if isinstance(func, ast.Name) and func.id == "print":
                    continue
                if isinstance(func, ast.Attribute) and func.attr == "sleep":
                    continue
            return False
        return True

    def _has_hardcoded_results(self, body: list[ast.stmt]) -> bool:
        """Check if function returns hardcoded dicts/lists with fake data."""
        for node in ast.walk(ast.Module(body=body, type_ignores=[])):
            if isinstance(node, ast.Return) and isinstance(node.value, ast.Dict):
                # Check if dict values are all constants
                if node.value.values and all(
                    isinstance(v, ast.Constant) for v in node.value.values
                ):
                    return True
        return False

    def _check_classes(self):
        """Check class definitions for mock patterns."""
        for node in ast.walk(self.tree):
            if isinstance(node, ast.ClassDef):
                name = node.name.lower()
                mock_indicators = ["mock", "fake", "stub", "dummy", "simulated"]
                if any(ind in name for ind in mock_indicators):
                    self.findings.append(Finding(
                        category=Category.MOCK_NAMING,
                        severity=Severity.HIGH,
                        message=f"Class '{node.name}' has mock/fake naming",
                        file_path=self.file_path,
                        line_number=node.lineno,
                        confidence=0.9,
                        suggestion="Use production class names for real exploit code",
                    ))

    def _get_source_lines(self, start: int, end: int) -> str:
        lines = self.source.split("\n")
        return "\n".join(lines[max(0, start - 1):min(len(lines), end)])


# ============================================================================
# PATTERN SCANNER (Multi-language regex analysis)
# ============================================================================

class PatternScanner:
    """
    Regex-based pattern scanner for detecting mock/fake exploit code.
    Works with any language.
    """

    def scan(self, content: str, file_path: str) -> list[Finding]:
        findings = []
        lines = content.split("\n")

        # Run all pattern groups
        for pattern, desc, conf in MOCK_NAME_PATTERNS:
            findings.extend(self._find_pattern(
                pattern, desc, conf, content, lines, file_path,
                Category.MOCK_NAMING, Severity.HIGH,
                "Rename to reflect production intent",
            ))

        for pattern, desc, conf in STUB_PATTERNS:
            findings.extend(self._find_pattern(
                pattern, desc, conf, content, lines, file_path,
                Category.STUB_IMPL, Severity.MEDIUM,
                "Implement actual security logic",
            ))

        for pattern, desc, conf in FAKE_DATA_PATTERNS:
            findings.extend(self._find_pattern(
                pattern, desc, conf, content, lines, file_path,
                Category.FAKE_DATA, Severity.HIGH,
                "Use realistic data or parameterize targets",
            ))

        for pattern, desc, conf in FAKE_CVE_PATTERNS:
            findings.extend(self._find_pattern(
                pattern, desc, conf, content, lines, file_path,
                Category.FAKE_CVE, Severity.CRITICAL,
                "Reference a real CVE ID",
            ))

        for pattern, desc, conf in TOY_PATTERNS:
            findings.extend(self._find_pattern(
                pattern, desc, conf, content, lines, file_path,
                Category.TOY_PATTERN, Severity.HIGH,
                "Replace toy patterns with production exploit logic",
            ))

        for pattern, desc, conf in SIMULATED_PAYLOAD_PATTERNS:
            findings.extend(self._find_pattern(
                pattern, desc, conf, content, lines, file_path,
                Category.SIMULATED_PAYLOAD, Severity.CRITICAL,
                "Use real payload construction",
            ))

        for pattern, desc, conf in WEAK_ERROR_PATTERNS:
            findings.extend(self._find_pattern(
                pattern, desc, conf, content, lines, file_path,
                Category.WEAK_ERROR_HANDLING, Severity.MEDIUM,
                "Handle specific exceptions with proper error reporting",
            ))

        return findings

    def _find_pattern(
        self,
        pattern: re.Pattern,
        description: str,
        confidence: float,
        content: str,
        lines: list[str],
        file_path: str,
        category: Category,
        severity: Severity,
        suggestion: str,
    ) -> list[Finding]:
        findings = []
        seen_lines = set()

        for match in pattern.finditer(content):
            line_num = content[:match.start()].count("\n") + 1

            # Skip if we already flagged this line for this pattern
            if line_num in seen_lines:
                continue
            seen_lines.add(line_num)

            # Reduce confidence if match is in a comment
            actual_conf = confidence
            if line_num <= len(lines):
                line_text = lines[line_num - 1].strip()
                if line_text.startswith("#") or line_text.startswith("//"):
                    actual_conf *= 0.6  # Comment context reduces confidence

            snippet = lines[line_num - 1].strip() if line_num <= len(lines) else None

            findings.append(Finding(
                category=category,
                severity=severity,
                message=description,
                file_path=file_path,
                line_number=line_num,
                code_snippet=snippet,
                confidence=actual_conf,
                suggestion=suggestion,
            ))

        return findings


# ============================================================================
# REALISM SCORER
# ============================================================================

class RealismScorer:
    """
    Computes a realism score (0-100) for a security test file.

    Score breakdown:
      - Start at 70 (assume decent by default)
      - Deductions for each finding (weighted by severity)
      - Bonuses for realism indicators (real libraries, proper error handling)
      - Floor at 0, ceiling at 100
    """

    SEVERITY_PENALTIES = {
        Severity.CRITICAL: 15,
        Severity.HIGH: 10,
        Severity.MEDIUM: 5,
        Severity.LOW: 2,
        Severity.INFO: 0,
    }

    def score(
        self,
        content: str,
        findings: list[Finding],
        has_network: bool = False,
        has_system: bool = False,
        has_crypto: bool = False,
        loc: int = 0,
    ) -> int:
        score = 70.0

        # Penalty for findings (capped per category to prevent runaway deductions)
        category_counts: dict[Category, int] = defaultdict(int)
        for f in findings:
            category_counts[f.category] += 1
            # Max 3 deductions per category
            if category_counts[f.category] <= 3:
                penalty = self.SEVERITY_PENALTIES.get(f.severity, 5)
                score -= penalty * f.confidence

        # Bonuses for realism indicators
        for pattern, desc, bonus in REALISM_INDICATORS:
            if pattern.search(content):
                score += bonus

        # Bonus for having actual network/system/crypto usage
        if has_network:
            score += 5
        if has_system:
            score += 3
        if has_crypto:
            score += 3

        # Bonus for file length (very short files are suspicious)
        if loc > 100:
            score += 5
        elif loc > 50:
            score += 2
        elif loc < 10:
            score -= 10

        # Clamp to 0-100
        return max(0, min(100, int(round(score))))


# ============================================================================
# COMPETITION READINESS CHECKER
# ============================================================================

# What each tool type MUST have to pass competition/enterprise validation
TOOL_REQUIREMENTS: dict[ToolType, dict[str, Any]] = {
    ToolType.EXPLOIT: {
        "label": "Exploit Tool",
        "required_capabilities": ["network", "error_handling", "parameterized_targets"],
        "recommended_capabilities": ["system", "crypto", "binary_ops"],
        "min_functions": 3,
        "min_loc": 50,
        "description": "Tools that exploit vulnerabilities must interact with real targets",
        "must_have_imports": [
            (r"socket|requests|urllib|http|scapy|impacket|pwntools|pwn|aiohttp|httpx",
             "Network library (socket, requests, scapy, impacket, etc.)"),
        ],
        "must_have_patterns": [
            (r"(?:argparse|sys\.argv|click\.option|typer)", "CLI argument handling for target specification"),
            (r"except\s+\w+Error", "Specific exception handling (not bare except)"),
        ],
    },
    ToolType.SCANNER: {
        "label": "Vulnerability Scanner",
        "required_capabilities": ["network", "error_handling", "output_formatting"],
        "recommended_capabilities": ["threading", "parameterized_targets"],
        "min_functions": 4,
        "min_loc": 60,
        "description": "Scanners must perform real network probes and parse responses",
        "must_have_imports": [
            (r"socket|requests|urllib|http|scapy|nmap|shodan|aiohttp|httpx",
             "Network/scanning library"),
        ],
        "must_have_patterns": [
            (r"(?:\.connect|\.send|\.recv|\.get\(|\.post\(|\.head\()",
             "Actual network operations (connect, send, recv, HTTP methods)"),
            (r"(?:json\.dumps|csv\.writer|print\(f|logging\.\w+|xml\.etree)",
             "Structured output/reporting"),
        ],
    },
    ToolType.FUZZER: {
        "label": "Fuzzer",
        "required_capabilities": ["mutation", "error_handling", "loop_construct"],
        "recommended_capabilities": ["network", "system", "crash_detection"],
        "min_functions": 3,
        "min_loc": 40,
        "description": "Fuzzers must mutate inputs and detect crashes/anomalies",
        "must_have_imports": [
            (r"random|os|struct|subprocess|ctypes",
             "Input mutation or system interaction library"),
        ],
        "must_have_patterns": [
            (r"(?:while\s|for\s.*in\s.*range|itertools)",
             "Iteration/loop construct for mutation cycles"),
            (r"(?:random\.\w+|bytearray|struct\.pack|os\.urandom|secrets\.)",
             "Data mutation operations"),
        ],
    },
    ToolType.CRYPTO: {
        "label": "Cryptographic Tool",
        "required_capabilities": ["crypto", "error_handling"],
        "recommended_capabilities": ["binary_ops", "parameterized_targets"],
        "min_functions": 2,
        "min_loc": 30,
        "description": "Crypto tools must use real cryptographic libraries, not toy XOR",
        "must_have_imports": [
            (r"cryptography|Crypto|hashlib|hmac|ssl|secrets|nacl",
             "Real cryptographic library (cryptography, PyCryptodome, hashlib, etc.)"),
        ],
        "must_have_patterns": [
            (r"(?:\.encrypt|\.decrypt|\.sign|\.verify|\.digest|\.hexdigest|PBKDF2|scrypt|bcrypt|Fernet|AES|RSA|ECDSA)",
             "Actual cryptographic operations"),
        ],
    },
    ToolType.FORENSIC: {
        "label": "Forensic Tool",
        "required_capabilities": ["file_io", "error_handling"],
        "recommended_capabilities": ["crypto", "output_formatting"],
        "min_functions": 3,
        "min_loc": 40,
        "description": "Forensic tools must parse real file formats and verify integrity",
        "must_have_imports": [
            (r"os|pathlib|hashlib|struct|mmap|binascii",
             "File/binary handling library"),
        ],
        "must_have_patterns": [
            (r"(?:open\(|Path\(|\.read_bytes|\.read_text|mmap\.mmap)",
             "Real file I/O operations"),
            (r"(?:hashlib\.\w+|\.hexdigest|\.digest|hmac\.)",
             "Hash verification for integrity"),
        ],
    },
    ToolType.RECON: {
        "label": "Reconnaissance Tool",
        "required_capabilities": ["network", "output_formatting"],
        "recommended_capabilities": ["threading", "parameterized_targets"],
        "min_functions": 3,
        "min_loc": 40,
        "description": "Recon tools must gather real information from targets",
        "must_have_imports": [
            (r"socket|requests|dns|whois|shodan|nmap|urllib|http|aiohttp",
             "Network/DNS/reconnaissance library"),
        ],
        "must_have_patterns": [
            (r"(?:\.resolve|\.query|gethostbyname|getaddrinfo|\.get\(|\.connect)",
             "Actual network/DNS queries"),
        ],
    },
    ToolType.GENERAL: {
        "label": "General Security Tool",
        "required_capabilities": ["error_handling"],
        "recommended_capabilities": ["parameterized_targets", "output_formatting"],
        "min_functions": 2,
        "min_loc": 20,
        "description": "Security tools must contain real operational logic",
        "must_have_imports": [],
        "must_have_patterns": [
            (r"except\s+\w+", "Some form of exception handling"),
        ],
    },
}

# Auto-detection keywords for tool type classification
TOOL_TYPE_SIGNALS: dict[ToolType, list[re.Pattern]] = {
    ToolType.EXPLOIT: [
        re.compile(r"exploit|payload|shellcode|overflow|injection|rce|reverse.?shell|bind.?shell", re.I),
    ],
    ToolType.SCANNER: [
        re.compile(r"scan(?:ner)?|probe|enumerate|port.?scan|vuln.?scan|nmap|discovery", re.I),
    ],
    ToolType.FUZZER: [
        re.compile(r"fuzz(?:er|ing)?|mutate|corpus|crash|seed|harness", re.I),
    ],
    ToolType.CRYPTO: [
        re.compile(r"encrypt|decrypt|cipher|hash|sign(?:ature)?|certificate|key.?gen|aes|rsa|ecdsa", re.I),
    ],
    ToolType.FORENSIC: [
        re.compile(r"forensic|evidence|carv(?:e|ing)|timeline|artifact|chain.?of.?custody|acquisition", re.I),
    ],
    ToolType.RECON: [
        re.compile(r"recon|reconnaissance|osint|footprint|whois|dns.?enum|subdomain", re.I),
    ],
}


class CompetitionReadinessChecker:
    """
    Validates that security code meets competition/enterprise standards.

    Instead of just finding what's WRONG (mock detection), this checker
    validates what SHOULD BE PRESENT for the code to be considered real.

    Use cases:
      - Students preparing code for cybersecurity competitions
      - Companies validating pentesting deliverables
      - Teams reviewing AI-generated security code before deployment
      - QA gates for red team tooling
    """

    def __init__(self):
        self._capability_patterns = {
            "network": re.compile(
                r"import\s+(?:socket|requests|urllib|http|scapy|impacket|pwntools|pwn|aiohttp|httpx|paramiko|ftplib|smtplib|telnetlib)"
                r"|from\s+(?:socket|requests|urllib|http|scapy|impacket|pwntools|pwn|aiohttp|httpx|paramiko|ftplib|smtplib|telnetlib)\b"
            ),
            "system": re.compile(
                r"import\s+(?:subprocess|ctypes|os|shutil|signal|winreg)"
                r"|from\s+(?:subprocess|ctypes|os|shutil|signal|winreg)\b"
            ),
            "crypto": re.compile(
                r"import\s+(?:cryptography|hashlib|hmac|ssl|secrets)"
                r"|from\s+(?:cryptography|Crypto|hashlib|hmac|ssl|secrets|nacl)\b"
            ),
            "binary_ops": re.compile(
                r"import\s+(?:struct|binascii|mmap|ctypes)"
                r"|from\s+(?:struct|binascii|mmap|ctypes)\b"
            ),
            "error_handling": re.compile(
                r"except\s+\w+(?:Error|Exception|Warning)\s*(?:as\s+\w+)?:"
            ),
            "parameterized_targets": re.compile(
                r"(?:argparse|sys\.argv|click\.option|click\.argument|typer\.Argument|typer\.Option|input\s*\()"
            ),
            "output_formatting": re.compile(
                r"(?:json\.dumps|csv\.writer|logging\.\w+|xml\.etree|print\(f['\"]|\.write\()"
            ),
            "threading": re.compile(
                r"(?:threading\.Thread|concurrent\.futures|asyncio\.gather|multiprocessing\.Pool)"
            ),
            "mutation": re.compile(
                r"(?:random\.\w+|bytearray|os\.urandom|secrets\.token|struct\.pack)"
            ),
            "loop_construct": re.compile(
                r"(?:while\s+\w|for\s+\w+\s+in\s|itertools\.)"
            ),
            "file_io": re.compile(
                r"(?:open\s*\(|Path\s*\(|\.read_bytes|\.read_text|mmap\.mmap|os\.walk)"
            ),
            "crash_detection": re.compile(
                r"(?:signal\.signal|SIGSEGV|SIGABRT|core\s*dump|traceback|atexit)"
            ),
        }

    def detect_tool_type(self, content: str, file_path: str) -> ToolType:
        """Auto-detect what type of security tool this file implements."""
        scores: dict[ToolType, int] = defaultdict(int)

        # Check filename
        fname = Path(file_path).stem.lower()
        for tool_type, patterns in TOOL_TYPE_SIGNALS.items():
            for pat in patterns:
                if pat.search(fname):
                    scores[tool_type] += 5  # Filename is strong signal

        # Check file content
        for tool_type, patterns in TOOL_TYPE_SIGNALS.items():
            for pat in patterns:
                matches = pat.findall(content)
                scores[tool_type] += len(matches)

        if not scores:
            return ToolType.GENERAL

        return max(scores, key=scores.get)

    def check_readiness(
        self,
        content: str,
        file_path: str,
        file_score: FileScore,
        tool_type: ToolType | None = None,
    ) -> CompetitionReport:
        """
        Run all competition readiness checks against a file.

        Args:
            content: File source code
            file_path: Path to the file
            file_score: The FileScore from the standard scan
            tool_type: Override auto-detection of tool type
        """
        if tool_type is None:
            tool_type = self.detect_tool_type(content, file_path)

        reqs = TOOL_REQUIREMENTS.get(tool_type, TOOL_REQUIREMENTS[ToolType.GENERAL])
        checks: list[ReadinessCheck] = []
        loc = len(content.split("\n"))

        # --- CHECK 1: No mock/fake identifiers ---
        mock_findings = [
            f for f in file_score.findings
            if f.category == Category.MOCK_NAMING
        ]
        if mock_findings:
            names = ", ".join(set(
                f.code_snippet.split("(")[0].split("=")[0].strip()
                for f in mock_findings[:3] if f.code_snippet
            ))
            checks.append(ReadinessCheck(
                check_id="CR-001",
                check_name="No Mock/Fake Identifiers",
                status=ReadinessStatus.FAIL,
                message=f"Found {len(mock_findings)} mock/fake identifier(s): {names}",
                fix="Rename all functions/variables/classes to reflect their real purpose. "
                    "Remove prefixes like mock_, fake_, dummy_, stub_, simulated_.",
                before_example="def mock_exploit(target):\ndef fake_scan(ip):\nclass DummyPayload:",
                after_example="def execute_exploit(target):\ndef scan_ports(ip):\nclass BufferOverflowPayload:",
                weight=1.0,
            ))
        else:
            checks.append(ReadinessCheck(
                check_id="CR-001",
                check_name="No Mock/Fake Identifiers",
                status=ReadinessStatus.PASS,
                message="No mock/fake naming patterns detected",
                weight=1.0,
            ))

        # --- CHECK 2: No placeholder data ---
        fake_data = [
            f for f in file_score.findings
            if f.category in (Category.FAKE_DATA, Category.FAKE_CVE)
        ]
        if fake_data:
            checks.append(ReadinessCheck(
                check_id="CR-002",
                check_name="No Placeholder Data",
                status=ReadinessStatus.FAIL,
                message=f"Found {len(fake_data)} placeholder data instance(s) (fake IPs, CVEs, hashes)",
                fix="Replace hardcoded test data with parameterized inputs. "
                    "Use argparse/click for target specification. "
                    "Reference real CVE IDs from NVD.",
                before_example='target = "192.168.1.1"\ncve = "CVE-2024-XXXXX"\nhash = "0" * 32',
                after_example='target = args.target  # from argparse\ncve = "CVE-2024-3400"  # real Palo Alto vuln\nhash = hashlib.sha256(data).hexdigest()',
                weight=0.9,
            ))
        else:
            checks.append(ReadinessCheck(
                check_id="CR-002",
                check_name="No Placeholder Data",
                status=ReadinessStatus.PASS,
                message="No fake IPs, CVEs, or placeholder data found",
                weight=0.9,
            ))

        # --- CHECK 3: No simulated payloads ---
        sim_payloads = [
            f for f in file_score.findings
            if f.category == Category.SIMULATED_PAYLOAD
        ]
        if sim_payloads:
            checks.append(ReadinessCheck(
                check_id="CR-003",
                check_name="No Simulated Payloads",
                status=ReadinessStatus.FAIL,
                message=f"Found {len(sim_payloads)} simulated payload(s) (hardcoded strings, empty shellcode)",
                fix="Build payloads programmatically using struct.pack, real encoding, "
                    "or framework-provided payload generators.",
                before_example='shellcode = ""\npayload = "test_payload"\nexploit_code = "hello"',
                after_example='shellcode = struct.pack("<I", ret_addr) + nop_sled + stage2\n'
                              'payload = build_payload(target_arch, callback_ip)\n'
                              'exploit_code = craft_request(vuln_param, overflow_len)',
                weight=1.0,
            ))
        else:
            checks.append(ReadinessCheck(
                check_id="CR-003",
                check_name="No Simulated Payloads",
                status=ReadinessStatus.PASS,
                message="No hardcoded/simulated payloads detected",
                weight=1.0,
            ))

        # --- CHECK 4: No always-pass/noop security functions ---
        bypass_findings = [
            f for f in file_score.findings
            if f.category in (Category.ALWAYS_PASS, Category.NOOP_FUNCTION)
        ]
        if bypass_findings:
            checks.append(ReadinessCheck(
                check_id="CR-004",
                check_name="No Bypass/Noop Functions",
                status=ReadinessStatus.FAIL,
                message=f"Found {len(bypass_findings)} trivial/always-pass security function(s)",
                fix="Implement actual logic in each security function. "
                    "Functions must perform real operations and return "
                    "computed results based on actual analysis.",
                before_example='def check_vulnerability(target):\n    return True\n\ndef exploit(ip):\n    pass',
                after_example='def check_vulnerability(target):\n    resp = requests.get(f"{target}/api/v1/debug")\n    return resp.status_code == 200 and "stack_trace" in resp.text\n\ndef exploit(ip):\n    sock = socket.socket()\n    sock.connect((ip, port))\n    sock.send(payload)',
                weight=1.0,
            ))
        else:
            checks.append(ReadinessCheck(
                check_id="CR-004",
                check_name="No Bypass/Noop Functions",
                status=ReadinessStatus.PASS,
                message="All security functions contain real logic",
                weight=1.0,
            ))

        # --- CHECK 5: No toy patterns (print-only, sleep-only) ---
        toy_findings = [
            f for f in file_score.findings
            if f.category == Category.TOY_PATTERN
        ]
        if toy_findings:
            checks.append(ReadinessCheck(
                check_id="CR-005",
                check_name="No Toy Patterns",
                status=ReadinessStatus.FAIL,
                message=f"Found {len(toy_findings)} toy pattern(s) (print-only functions, sleep simulations)",
                fix="Replace print statements with actual operations. "
                    "Use logging for status messages, not print() as the only action.",
                before_example='def attack(target):\n    print("Exploiting target...")\n    time.sleep(2)\n    print("Success!")',
                after_example='def attack(target):\n    log.info("Connecting to %s", target)\n    sock = socket.create_connection((target, 80))\n    sock.send(crafted_request)\n    response = sock.recv(4096)\n    return parse_response(response)',
                weight=0.9,
            ))
        else:
            checks.append(ReadinessCheck(
                check_id="CR-005",
                check_name="No Toy Patterns",
                status=ReadinessStatus.PASS,
                message="No print-only or sleep-only functions found",
                weight=0.9,
            ))

        # --- CHECK 6: Required imports present ---
        for import_pattern, import_desc in reqs.get("must_have_imports", []):
            if re.search(import_pattern, content):
                checks.append(ReadinessCheck(
                    check_id="CR-006",
                    check_name=f"Required Import: {import_desc}",
                    status=ReadinessStatus.PASS,
                    message=f"Found required import: {import_desc}",
                    weight=0.8,
                ))
            else:
                checks.append(ReadinessCheck(
                    check_id="CR-006",
                    check_name=f"Required Import: {import_desc}",
                    status=ReadinessStatus.FAIL,
                    message=f"Missing required import for {reqs['label']}: {import_desc}",
                    fix=f"Add an import for a {import_desc.lower()}. "
                        f"A {reqs['label'].lower()} must use real libraries to interact with targets.",
                    weight=0.8,
                ))

        # --- CHECK 7: Required code patterns present ---
        for code_pattern, code_desc in reqs.get("must_have_patterns", []):
            if re.search(code_pattern, content):
                checks.append(ReadinessCheck(
                    check_id="CR-007",
                    check_name=f"Required Pattern: {code_desc}",
                    status=ReadinessStatus.PASS,
                    message=f"Found: {code_desc}",
                    weight=0.7,
                ))
            else:
                checks.append(ReadinessCheck(
                    check_id="CR-007",
                    check_name=f"Required Pattern: {code_desc}",
                    status=ReadinessStatus.FAIL,
                    message=f"Missing: {code_desc}",
                    fix=f"A {reqs['label'].lower()} must include {code_desc.lower()}.",
                    weight=0.7,
                ))

        # --- CHECK 8: Required capabilities present ---
        detected_caps = set()
        for cap_name, cap_pattern in self._capability_patterns.items():
            if cap_pattern.search(content):
                detected_caps.add(cap_name)

        for req_cap in reqs.get("required_capabilities", []):
            if req_cap in detected_caps:
                checks.append(ReadinessCheck(
                    check_id="CR-008",
                    check_name=f"Capability: {req_cap}",
                    status=ReadinessStatus.PASS,
                    message=f"Required capability '{req_cap}' is present",
                    weight=0.8,
                ))
            else:
                cap_advice = {
                    "network": "Add socket, requests, or scapy for network operations",
                    "system": "Add subprocess, ctypes, or os for system interaction",
                    "crypto": "Add cryptography, hashlib, or PyCryptodome for crypto ops",
                    "error_handling": "Add try/except blocks with specific exception types",
                    "parameterized_targets": "Add argparse or click for target specification",
                    "output_formatting": "Add structured output (JSON, CSV, or logging)",
                    "mutation": "Add random, bytearray, or struct for input mutation",
                    "file_io": "Add file reading with open() or pathlib.Path",
                    "binary_ops": "Add struct or ctypes for binary data handling",
                    "threading": "Add threading or asyncio for concurrent operations",
                    "loop_construct": "Add iteration loops for mutation/scan cycles",
                    "crash_detection": "Add signal handling or exception monitoring",
                }
                checks.append(ReadinessCheck(
                    check_id="CR-008",
                    check_name=f"Capability: {req_cap}",
                    status=ReadinessStatus.FAIL,
                    message=f"Missing required capability: {req_cap}",
                    fix=cap_advice.get(req_cap, f"Add {req_cap} capability"),
                    weight=0.8,
                ))

        # Recommended capabilities (warnings only)
        for rec_cap in reqs.get("recommended_capabilities", []):
            if rec_cap in detected_caps:
                checks.append(ReadinessCheck(
                    check_id="CR-009",
                    check_name=f"Recommended: {rec_cap}",
                    status=ReadinessStatus.PASS,
                    message=f"Recommended capability '{rec_cap}' is present",
                    weight=0.3,
                ))
            else:
                checks.append(ReadinessCheck(
                    check_id="CR-009",
                    check_name=f"Recommended: {rec_cap}",
                    status=ReadinessStatus.WARN,
                    message=f"Missing recommended capability: {rec_cap} (not required, but strengthens score)",
                    weight=0.3,
                ))

        # --- CHECK 10: Minimum complexity ---
        min_funcs = reqs.get("min_functions", 2)
        if file_score.functions_analyzed >= min_funcs:
            checks.append(ReadinessCheck(
                check_id="CR-010",
                check_name="Minimum Complexity (Functions)",
                status=ReadinessStatus.PASS,
                message=f"Has {file_score.functions_analyzed} functions (minimum: {min_funcs})",
                weight=0.5,
            ))
        else:
            checks.append(ReadinessCheck(
                check_id="CR-010",
                check_name="Minimum Complexity (Functions)",
                status=ReadinessStatus.FAIL if file_score.functions_analyzed == 0 else ReadinessStatus.WARN,
                message=f"Only {file_score.functions_analyzed} functions found (recommended minimum: {min_funcs})",
                fix=f"A {reqs['label'].lower()} should have at least {min_funcs} "
                    f"distinct functions showing modular design.",
                weight=0.5,
            ))

        min_loc = reqs.get("min_loc", 20)
        if loc >= min_loc:
            checks.append(ReadinessCheck(
                check_id="CR-011",
                check_name="Minimum Complexity (LOC)",
                status=ReadinessStatus.PASS,
                message=f"File has {loc} lines (minimum: {min_loc})",
                weight=0.4,
            ))
        else:
            checks.append(ReadinessCheck(
                check_id="CR-011",
                check_name="Minimum Complexity (LOC)",
                status=ReadinessStatus.WARN,
                message=f"File only has {loc} lines (recommended minimum: {min_loc})",
                fix="Ensure the tool has sufficient depth - real security tools aren't one-liners.",
                weight=0.4,
            ))

        # --- CHECK 12: No weak error handling ---
        weak_err = [
            f for f in file_score.findings
            if f.category == Category.WEAK_ERROR_HANDLING
        ]
        if weak_err:
            checks.append(ReadinessCheck(
                check_id="CR-012",
                check_name="Proper Error Handling",
                status=ReadinessStatus.FAIL,
                message=f"Found {len(weak_err)} bare/broad except handler(s)",
                fix="Replace bare 'except:' with specific exception types. "
                    "Competition scanners flag swallowed exceptions as a sign of fake code.",
                before_example="try:\n    sock.connect(target)\nexcept:\n    pass",
                after_example="try:\n    sock.connect((host, port))\nexcept ConnectionRefusedError:\n    log.warning('Port %d closed on %s', port, host)\nexcept socket.timeout:\n    log.warning('Connection timed out')",
                weight=0.7,
            ))
        else:
            checks.append(ReadinessCheck(
                check_id="CR-012",
                check_name="Proper Error Handling",
                status=ReadinessStatus.PASS,
                message="No bare/broad exception handlers found",
                weight=0.7,
            ))

        # --- CHECK 13: No stub implementations ---
        stubs = [
            f for f in file_score.findings
            if f.category == Category.STUB_IMPL
            and f.confidence >= 0.7  # Only high-confidence stubs
        ]
        if stubs:
            checks.append(ReadinessCheck(
                check_id="CR-013",
                check_name="No Stub Implementations",
                status=ReadinessStatus.FAIL,
                message=f"Found {len(stubs)} stub/unfinished implementation(s)",
                fix="Complete all NotImplementedError, TODO, and pass-only functions. "
                    "Competition scanners reject code with unfinished stubs.",
                weight=0.9,
            ))
        else:
            checks.append(ReadinessCheck(
                check_id="CR-013",
                check_name="No Stub Implementations",
                status=ReadinessStatus.PASS,
                message="No stub implementations detected",
                weight=0.9,
            ))

        # --- Compute overall verdict ---
        total_weight = sum(c.weight for c in checks)
        pass_weight = sum(c.weight for c in checks if c.status == ReadinessStatus.PASS)
        fail_count = sum(1 for c in checks if c.status == ReadinessStatus.FAIL)
        critical_fails = sum(
            1 for c in checks
            if c.status == ReadinessStatus.FAIL and c.weight >= 0.9
        )

        pass_ratio = pass_weight / total_weight if total_weight > 0 else 0.0

        # Adjust probability based on realism score too
        score_factor = file_score.realism_score / 100.0
        pass_probability = (pass_ratio * 0.6) + (score_factor * 0.4)

        if critical_fails > 0:
            verdict = "WILL FAIL"
            pass_probability = min(pass_probability, 0.25)
        elif fail_count > 2:
            verdict = "NEEDS WORK"
            pass_probability = min(pass_probability, 0.55)
        elif fail_count > 0:
            verdict = "NEEDS WORK"
        elif pass_probability >= 0.85:
            verdict = "COMPETITION READY"
        else:
            verdict = "NEEDS WORK"

        # Build remediation summary (ordered by priority)
        remediation = []
        for c in sorted(checks, key=lambda x: -x.weight):
            if c.status == ReadinessStatus.FAIL and c.fix:
                remediation.append(f"[{c.check_id}] {c.fix}")

        return CompetitionReport(
            file_path=file_path,
            detected_tool_type=reqs["label"],
            overall_verdict=verdict,
            pass_probability=pass_probability,
            realism_score=file_score.realism_score,
            checks=checks,
            remediation_summary=remediation,
        )


# ============================================================================
# MAIN SCANNER ENGINE
# ============================================================================

class ExploitRealismScanner:
    """
    Main scanner engine. Orchestrates AST analysis, pattern scanning,
    and realism scoring across a codebase.
    """

    def __init__(
        self,
        min_confidence: float = 0.5,
        min_score: int = 0,
        strict: bool = False,
    ):
        self.min_confidence = min_confidence
        self.min_score = min_score
        self.strict = strict
        self.pattern_scanner = PatternScanner()
        self.realism_scorer = RealismScorer()

    def scan_file(self, file_path: Path) -> FileScore | None:
        """Scan a single file and return its realism score."""
        if not file_path.exists() or not file_path.is_file():
            return None

        if file_path.suffix.lower() not in SECURITY_EXTENSIONS:
            return None

        try:
            content = file_path.read_text(encoding="utf-8", errors="ignore")
        except OSError:
            return None

        if not content.strip():
            return None

        loc = len(content.split("\n"))
        findings: list[Finding] = []
        has_network = False
        has_system = False
        has_crypto = False
        functions_analyzed = 0

        # Pattern scan (all languages)
        pattern_findings = self.pattern_scanner.scan(content, str(file_path))
        findings.extend(pattern_findings)

        # AST analysis (Python only)
        if file_path.suffix == ".py":
            ast_analyzer = ASTAnalyzer(content, str(file_path))
            ast_findings = ast_analyzer.analyze()
            findings.extend(ast_findings)
            has_network = ast_analyzer.has_network
            has_system = ast_analyzer.has_system
            has_crypto = ast_analyzer.has_crypto
            functions_analyzed = ast_analyzer.functions_analyzed

        # Filter by confidence
        findings = [f for f in findings if f.confidence >= self.min_confidence]

        # Deduplicate (same line + same category)
        seen = set()
        deduped = []
        for f in findings:
            key = (f.file_path, f.line_number, f.category)
            if key not in seen:
                seen.add(key)
                deduped.append(f)
        findings = deduped

        # Compute realism score
        realism = self.realism_scorer.score(
            content, findings,
            has_network=has_network,
            has_system=has_system,
            has_crypto=has_crypto,
            loc=loc,
        )

        # Check for realism indicators to flag real payloads
        has_real_payloads = any(
            p.search(content) for p, _, _ in REALISM_INDICATORS
            if _ >= 10  # Only count strong indicators
        )

        return FileScore(
            file_path=str(file_path),
            realism_score=realism,
            findings=findings,
            lines_of_code=loc,
            functions_analyzed=functions_analyzed,
            has_network_calls=has_network,
            has_system_calls=has_system,
            has_crypto_ops=has_crypto,
            has_real_payloads=has_real_payloads,
        )

    def scan_directory(self, directory: Path, recursive: bool = True) -> ScanReport:
        """Scan an entire directory and produce a report."""
        start_time = time.time()
        report = ScanReport(scan_path=str(directory))

        skip_dirs = {
            ".git", ".svn", "node_modules", "__pycache__", ".pytest_cache",
            "venv", ".venv", ".tox", "dist", "build", ".idea", ".vscode",
            ".cache", "vendor", "packages", ".mypy_cache", ".ruff_cache",
            "egg-info",
        }

        files_to_scan: list[Path] = []

        if directory.is_file():
            files_to_scan = [directory]
        else:
            for root, dirs, files in (directory.rglob("*") if False else [(None, None, None)]):
                pass  # Using manual walk for skip_dirs support

            for root, dirs, files in __import__("os").walk(directory):
                root_path = Path(root)
                dirs[:] = [d for d in dirs if d not in skip_dirs]
                for f in files:
                    fp = root_path / f
                    if fp.suffix.lower() in SECURITY_EXTENSIONS:
                        files_to_scan.append(fp)
                if not recursive:
                    break

        category_counts: dict[str, int] = defaultdict(int)

        for fp in files_to_scan:
            file_score = self.scan_file(fp)
            if file_score is None:
                continue

            report.files_scanned += 1

            if file_score.findings:
                report.files_flagged += 1
                report.file_scores.append(file_score)
                report.total_findings += len(file_score.findings)
                report.critical_findings += sum(
                    1 for f in file_score.findings if f.severity == Severity.CRITICAL
                )
                for f in file_score.findings:
                    category_counts[f.category.value] += 1
            elif file_score.realism_score < 60:
                # Low score even without specific findings
                report.files_flagged += 1
                report.file_scores.append(file_score)

        report.category_breakdown = dict(category_counts)
        report.scan_duration_seconds = time.time() - start_time

        if report.file_scores:
            report.average_realism_score = sum(
                fs.realism_score for fs in report.file_scores
            ) / len(report.file_scores)
        else:
            report.average_realism_score = 100.0

        return report

    def scan_path(self, path: Path) -> ScanReport:
        """Scan a file or directory."""
        if path.is_file():
            report = ScanReport(scan_path=str(path))
            file_score = self.scan_file(path)
            if file_score:
                report.files_scanned = 1
                if file_score.findings or file_score.realism_score < 60:
                    report.files_flagged = 1
                    report.file_scores = [file_score]
                    report.total_findings = len(file_score.findings)
                    report.critical_findings = sum(
                        1 for f in file_score.findings if f.severity == Severity.CRITICAL
                    )
                    report.average_realism_score = file_score.realism_score
                    for f in file_score.findings:
                        report.category_breakdown[f.category.value] = (
                            report.category_breakdown.get(f.category.value, 0) + 1
                        )
                else:
                    report.average_realism_score = file_score.realism_score
            return report
        return self.scan_directory(path)


# ============================================================================
# TERMINAL OUTPUT
# ============================================================================

def print_terminal_report(report: ScanReport):
    """Print a formatted report to the terminal."""
    W = 70

    print("\n" + "=" * W)
    print("  EXPLOIT REALISM SCANNER (ERS) - RESULTS")
    print("=" * W)
    print(f"  Target:    {report.scan_path}")
    print(f"  Files:     {report.files_scanned} scanned, {report.files_flagged} flagged")
    print(f"  Findings:  {report.total_findings} total, {report.critical_findings} critical")
    print(f"  Avg Score: {report.average_realism_score:.0f}/100")
    print(f"  Duration:  {report.scan_duration_seconds:.2f}s")
    print("-" * W)

    if report.category_breakdown:
        print("\n  CATEGORY BREAKDOWN:")
        for cat, count in sorted(report.category_breakdown.items(), key=lambda x: -x[1]):
            bar = "#" * min(count, 30)
            print(f"    {cat:<25s} {count:>3d}  {bar}")

    if not report.file_scores:
        print("\n  No issues found. All files appear production-grade.")
        print("=" * W + "\n")
        return

    print("\n  FILE RESULTS (sorted by realism score):")
    print("-" * W)

    for fs in sorted(report.file_scores, key=lambda x: x.realism_score):
        grade_colors = {"A": "+", "B": "+", "C": "~", "D": "-", "F": "!"}
        mark = grade_colors.get(fs.grade, "?")
        status_line = (
            f"  [{fs.grade}] {fs.file_path}"
        )
        print(f"\n{status_line}")
        score_bar = "#" * (fs.realism_score // 2) + "." * (50 - fs.realism_score // 2)
        print(f"      Score: {fs.realism_score}/100  [{score_bar}]")

        capabilities = []
        if fs.has_network_calls:
            capabilities.append("NET")
        if fs.has_system_calls:
            capabilities.append("SYS")
        if fs.has_crypto_ops:
            capabilities.append("CRYPTO")
        if capabilities:
            print(f"      Capabilities: {', '.join(capabilities)}")

        if fs.findings:
            # Group by severity
            by_sev = defaultdict(list)
            for f in fs.findings:
                by_sev[f.severity].append(f)

            for sev in [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM, Severity.LOW]:
                if sev not in by_sev:
                    continue
                for f in by_sev[sev][:5]:  # Max 5 per severity
                    line_str = f"L{f.line_number}" if f.line_number else "L?"
                    print(f"      [{sev.value:>8s}] {line_str:>5s}  {f.message[:55]}")
                remaining = len(by_sev[sev]) - 5
                if remaining > 0:
                    print(f"      ... and {remaining} more {sev.value} findings")

    print("\n" + "=" * W)

    # Summary verdict
    if report.average_realism_score >= 75:
        print("  VERDICT: Code appears mostly production-grade")
    elif report.average_realism_score >= 50:
        print("  VERDICT: Code has significant mock/simulated components")
    else:
        print("  VERDICT: Code is predominantly mock/fake - NOT suitable for real testing")

    if report.critical_findings > 0:
        print(f"  WARNING: {report.critical_findings} critical findings require attention")

    print("=" * W + "\n")


def print_competition_report(comp_report: CompetitionReport):
    """Print a formatted competition readiness report to the terminal."""
    W = 70

    print("\n" + "=" * W)
    print("  COMPETITION READINESS CHECKER")
    print("=" * W)
    print(f"  File:       {comp_report.file_path}")
    print(f"  Tool Type:  {comp_report.detected_tool_type}")
    print(f"  Realism:    {comp_report.realism_score}/100")
    print(f"  Pass Prob:  {comp_report.pass_probability:.0%}")
    print("-" * W)

    # Verdict banner
    if comp_report.overall_verdict == "COMPETITION READY":
        print("\n  >>> VERDICT: COMPETITION READY <<<")
        print("  This code should pass competition integrity scanners.")
    elif comp_report.overall_verdict == "NEEDS WORK":
        print("\n  >>> VERDICT: NEEDS WORK <<<")
        print("  Fix the items below before submitting.")
    else:
        print("\n  >>> VERDICT: WILL FAIL <<<")
        print("  Critical issues detected. Code will be disqualified.")

    # Checklist
    print(f"\n  CHECKLIST ({sum(1 for c in comp_report.checks if c.status == ReadinessStatus.PASS)}"
          f"/{len(comp_report.checks)} passed):")
    print("-" * W)

    for c in comp_report.checks:
        icon = {"PASS": "[OK]", "FAIL": "[XX]", "WARN": "[!!]"}[c.status.value]
        # Truncate message to fit
        msg = c.message[:50]
        print(f"  {icon} {c.check_name:<35s}  {msg}")

    # Failing checks with fixes
    fails = [c for c in comp_report.checks if c.status == ReadinessStatus.FAIL]
    if fails:
        print(f"\n  REQUIRED FIXES ({len(fails)}):")
        print("-" * W)
        for i, c in enumerate(fails, 1):
            print(f"\n  {i}. {c.check_name}")
            print(f"     Problem: {c.message}")
            if c.fix:
                # Word-wrap the fix text
                fix_words = c.fix.split()
                fix_lines = []
                current = "     Fix: "
                for word in fix_words:
                    if len(current) + len(word) + 1 > W - 2:
                        fix_lines.append(current)
                        current = "          " + word
                    else:
                        current += (" " if current.strip() else "") + word
                fix_lines.append(current)
                for line in fix_lines:
                    print(line)

            if c.before_example and c.after_example:
                print(f"     Before:")
                for line in c.before_example.split("\n")[:3]:
                    print(f"       | {line}")
                print(f"     After:")
                for line in c.after_example.split("\n")[:3]:
                    print(f"       | {line}")

    # Warnings
    warns = [c for c in comp_report.checks if c.status == ReadinessStatus.WARN]
    if warns:
        print(f"\n  RECOMMENDATIONS ({len(warns)}):")
        for c in warns:
            print(f"    - {c.check_name}: {c.message[:55]}")

    # Remediation summary
    if comp_report.remediation_summary:
        print(f"\n  PRIORITY FIX ORDER:")
        print("-" * W)
        for i, step in enumerate(comp_report.remediation_summary[:8], 1):
            print(f"  {i}. {step[:65]}")

    print("\n" + "=" * W + "\n")


# ============================================================================
# CLI
# ============================================================================

def main():
    import argparse

    parser = argparse.ArgumentParser(
        description="Exploit Realism Scanner - Detect fake/mock exploit code",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s ./tests/security/
  %(prog)s exploit.py --output report.json
  %(prog)s ./pentest/ --format markdown --output report.md
  %(prog)s ./vuln_tests/ --strict --min-score 70
  %(prog)s ./exploits/ --min-confidence 0.7
  %(prog)s exploit.py --competition
  %(prog)s exploit.py --competition --tool-type exploit
  %(prog)s ./project/ --competition --output readiness.md --format markdown
        """,
    )
    parser.add_argument("path", help="File or directory to scan")
    parser.add_argument("--output", "-o", help="Output file path (JSON or Markdown)")
    parser.add_argument(
        "--format", "-f", choices=["terminal", "json", "markdown"],
        default="terminal", help="Output format (default: terminal)",
    )
    parser.add_argument(
        "--min-confidence", type=float, default=0.5,
        help="Minimum confidence threshold (0.0-1.0, default: 0.5)",
    )
    parser.add_argument(
        "--min-score", type=int, default=0,
        help="Minimum realism score to pass (0-100, default: 0)",
    )
    parser.add_argument(
        "--strict", action="store_true",
        help="Strict mode: exit code 1 if any file scores below --min-score",
    )
    parser.add_argument(
        "--competition", "-c", action="store_true",
        help="Competition readiness mode: checks what SHOULD be present, "
             "provides remediation checklist with before/after examples",
    )
    parser.add_argument(
        "--tool-type", "-t",
        choices=["exploit", "scanner", "fuzzer", "crypto_tool", "forensic", "recon", "general_security"],
        default=None,
        help="Override auto-detected tool type (default: auto-detect)",
    )

    args = parser.parse_args()
    target = Path(args.path)

    if not target.exists():
        print(f"Error: {target} does not exist")
        sys.exit(2)

    scanner = ExploitRealismScanner(
        min_confidence=args.min_confidence,
        min_score=args.min_score,
        strict=args.strict,
    )

    # --- Competition Readiness Mode ---
    if args.competition:
        checker = CompetitionReadinessChecker()
        tool_type_override = ToolType(args.tool_type) if args.tool_type else None

        comp_reports: list[CompetitionReport] = []

        if target.is_file():
            file_score = scanner.scan_file(target)
            if file_score is None:
                print(f"Error: Could not scan {target}")
                sys.exit(2)
            content = target.read_text(encoding="utf-8", errors="ignore")
            cr = checker.check_readiness(content, str(target), file_score, tool_type_override)
            comp_reports.append(cr)
        else:
            # Scan directory, run readiness check on each flagged file
            report = scanner.scan_path(target)
            for fs in report.file_scores:
                fp = Path(fs.file_path)
                try:
                    content = fp.read_text(encoding="utf-8", errors="ignore")
                except OSError:
                    continue
                cr = checker.check_readiness(content, fs.file_path, fs, tool_type_override)
                comp_reports.append(cr)

            # Also check clean files (they might be missing capabilities)
            if target.is_dir():
                import os as _os
                for root, dirs, files in _os.walk(target):
                    dirs[:] = [d for d in dirs if d not in {
                        ".git", "__pycache__", "node_modules", "venv", ".venv",
                        "dist", "build", ".tox",
                    }]
                    for f in files:
                        fp = Path(root) / f
                        if fp.suffix.lower() not in SECURITY_EXTENSIONS:
                            continue
                        # Skip already-processed files
                        if str(fp) in {cr.file_path for cr in comp_reports}:
                            continue
                        fs = scanner.scan_file(fp)
                        if fs is None:
                            continue
                        try:
                            content = fp.read_text(encoding="utf-8", errors="ignore")
                        except OSError:
                            continue
                        cr = checker.check_readiness(content, str(fp), fs, tool_type_override)
                        comp_reports.append(cr)

        # Output competition reports
        if args.format == "json" or (args.output and args.output.endswith(".json")):
            data = [cr.to_dict() for cr in comp_reports]
            json_data = json.dumps(data if len(data) > 1 else data[0], indent=2)
            if args.output:
                Path(args.output).write_text(json_data)
                print(f"Competition readiness report written to {args.output}")
            else:
                print(json_data)

        elif args.format == "markdown" or (args.output and args.output.endswith(".md")):
            md_parts = [cr.to_markdown() for cr in comp_reports]
            md = "\n\n---\n\n".join(md_parts)
            if args.output:
                Path(args.output).write_text(md)
                print(f"Competition readiness report written to {args.output}")
            else:
                print(md)

        else:
            for cr in comp_reports:
                print_competition_report(cr)
            if args.output:
                data = [cr.to_dict() for cr in comp_reports]
                json_data = json.dumps(data if len(data) > 1 else data[0], indent=2)
                Path(args.output).write_text(json_data)
                print(f"JSON report also written to {args.output}")

        # Exit code: fail if any file has "WILL FAIL" verdict
        will_fail = [cr for cr in comp_reports if cr.overall_verdict == "WILL FAIL"]
        if will_fail:
            sys.exit(1)
        sys.exit(0)

    # --- Standard Scan Mode ---
    report = scanner.scan_path(target)

    # Output
    if args.format == "json" or (args.output and args.output.endswith(".json")):
        json_data = json.dumps(report.to_dict(), indent=2)
        if args.output:
            Path(args.output).write_text(json_data)
            print(f"Report written to {args.output}")
        else:
            print(json_data)

    elif args.format == "markdown" or (args.output and args.output.endswith(".md")):
        md = report.to_markdown()
        if args.output:
            Path(args.output).write_text(md)
            print(f"Report written to {args.output}")
        else:
            print(md)

    else:
        print_terminal_report(report)
        if args.output:
            json_data = json.dumps(report.to_dict(), indent=2)
            Path(args.output).write_text(json_data)
            print(f"JSON report also written to {args.output}")

    # Exit code for CI/CD
    if args.strict:
        failing = [
            fs for fs in report.file_scores
            if fs.realism_score < args.min_score
        ]
        if failing:
            print(f"\nSTRICT MODE: {len(failing)} file(s) below minimum score {args.min_score}")
            sys.exit(1)

    if report.critical_findings > 0:
        sys.exit(1)

    sys.exit(0)


if __name__ == "__main__":
    main()
